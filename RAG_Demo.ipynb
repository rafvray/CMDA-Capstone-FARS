{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180d5503",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb13733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Demo tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"✅ Demo tools loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba7569",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6132908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/xxvzrlmd0wddkflz97l7nq7r0000gn/T/ipykernel_11152/813670556.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model 'sentence-transformers/all-MiniLM-L6-v2' is loaded and ready.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the open-source embedding model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "print(f\"✅ Model '{model_name}' is loaded and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12347d83",
   "metadata": {},
   "source": [
    "### **Text-to-Vector**\n",
    "*(Main component of RAG)*\n",
    "\n",
    "Here is a plain English question being converted to numeric vector.\n",
    "\n",
    "**\"How many accidents in Virginia involved alcohol?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693823c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Your Question ---\n",
      "'How many accidents in Virginia involved alcohol?'\n",
      "\n",
      "--- Becomes a 'Vector' (a list of numbers) ---\n",
      "[ 8.25532675e-02  7.39611080e-03  1.54931024e-02  2.28705741e-02\n",
      "  3.94746102e-02  1.02309123e-01 -2.83401608e-02  1.93100106e-02\n",
      " -6.40363097e-02  3.13794166e-02  7.02017099e-02 -3.06326542e-02\n",
      " -3.37345451e-02  3.43769714e-02 -4.58711274e-02 -1.94535460e-02\n",
      "  7.81070860e-03 -4.56623957e-02 -2.20975243e-02  1.99681204e-02\n",
      " -1.71534829e-02  2.57411618e-02  6.69329613e-02 -1.41509240e-02\n",
      " -6.80635357e-03  2.49181110e-02 -5.12567023e-03  7.08811209e-02\n",
      "  1.24479868e-02 -4.45041135e-02  1.95077322e-02  1.39297610e-02\n",
      "  1.87728778e-02  8.95657169e-04 -1.95257701e-02 -1.02194510e-01\n",
      "  5.49994037e-02  5.42069264e-02  4.48841155e-02  1.21720489e-02\n",
      "  1.54754017e-02 -3.69361527e-02  2.77480520e-02  1.40515668e-02\n",
      "  1.14831431e-02 -1.33910319e-02 -5.47143258e-02  1.45685999e-02\n",
      "  3.93598080e-02  1.14458902e-02  5.54015972e-02  3.19396779e-02\n",
      "  1.83511768e-02  7.18316622e-03  7.53954202e-02 -1.72937989e-01\n",
      " -3.28589715e-02  7.18956441e-02  9.18856543e-03  6.82864115e-02\n",
      "  2.18900722e-02  5.26492894e-02 -6.26147389e-02  2.49456111e-02\n",
      "  1.18428012e-02 -1.82538584e-04 -6.38366770e-03 -3.99573520e-02\n",
      "  7.17717037e-03  1.25803677e-02 -1.65892635e-02 -5.27415276e-02\n",
      " -4.70278598e-03 -5.00455536e-02 -4.91735563e-02 -3.98675427e-02\n",
      "  3.49377953e-02  4.43196930e-02  2.58755740e-02 -2.60229092e-02\n",
      " -7.34645352e-02 -3.92763242e-02  1.79139599e-02  6.01687990e-02\n",
      "  4.60899584e-02 -3.40454094e-02 -7.60202929e-02  7.06331134e-02\n",
      " -6.91658584e-04  3.59639600e-02 -7.84595609e-02 -3.59485112e-02\n",
      "  9.34908912e-02 -9.60580111e-02  5.76527193e-02  9.40804109e-02\n",
      " -3.07651535e-02 -1.70066096e-02  6.30501360e-02 -1.24713304e-02\n",
      " -1.33249937e-02  2.06980780e-02 -2.31351797e-02 -4.40213494e-02\n",
      "  5.95578663e-02  3.64765674e-02  1.12809511e-02  4.38554250e-02\n",
      " -3.70999263e-03 -3.49888317e-02  2.49108952e-02  7.05752596e-02\n",
      "  7.74168968e-02 -5.67535199e-02  3.87962684e-02  3.78560200e-02\n",
      "  1.12391366e-02  1.48707221e-03 -3.94765241e-03 -2.87602637e-02\n",
      " -5.48655353e-02  3.31571922e-02  3.13128121e-02  1.60896797e-02\n",
      " -1.01044573e-01 -1.33812437e-02 -2.79655494e-02 -5.25367253e-33\n",
      "  4.83784499e-03 -1.24398164e-01 -4.96266484e-02  5.17202914e-02\n",
      "  1.00186683e-01 -7.07263649e-02 -5.14205955e-02 -5.32887094e-02\n",
      "  2.18424071e-02 -2.06791218e-02  3.23790051e-02 -8.50521922e-02\n",
      " -3.22033390e-02 -6.88583031e-02  9.35210362e-02  1.14802225e-02\n",
      " -4.91683930e-02  3.17078158e-02 -1.32757470e-01 -6.30400330e-02\n",
      " -9.48402062e-02 -4.75991666e-02  1.16531895e-02  6.37522936e-02\n",
      " -5.04307486e-02  4.19113114e-02  2.70944219e-02  1.85189992e-02\n",
      "  5.73402792e-02 -3.39680864e-03  3.13520767e-02  1.07042298e-01\n",
      "  3.58085893e-02  1.11284293e-02  7.45526627e-02  8.89434442e-02\n",
      " -2.46942025e-02  9.57456417e-03 -4.20814753e-02 -1.95989665e-02\n",
      " -1.98609270e-02  4.50301208e-02  3.48130725e-02  2.46363357e-02\n",
      "  4.63041011e-03 -5.51258260e-03 -9.76973623e-02 -5.57475872e-02\n",
      "  1.03388289e-02  2.38332544e-02 -6.18453361e-02  3.23295593e-03\n",
      " -6.63396204e-03 -2.13026833e-02 -7.38713667e-02  1.11556523e-01\n",
      "  2.26213336e-02  4.52296697e-02  3.44145037e-02  6.38825521e-02\n",
      " -3.69707532e-02  1.01222485e-01 -3.16729061e-02 -2.32904181e-02\n",
      " -9.28494707e-03 -1.72251705e-02  2.26441827e-02 -6.28186166e-02\n",
      " -2.06426643e-02 -4.45495769e-02 -2.95488201e-02  1.00016803e-01\n",
      " -5.44975661e-02 -1.24880828e-01 -4.36321124e-02  5.87566532e-02\n",
      "  3.24467570e-02 -1.11595020e-01  2.24518720e-02 -2.13481896e-02\n",
      " -5.87143227e-02 -9.97612476e-02  3.78170572e-02  2.61095818e-02\n",
      "  1.26481615e-03 -2.32270528e-02 -2.69276295e-02 -5.87697923e-02\n",
      " -3.78416888e-02 -2.52092667e-02 -2.45311465e-02 -1.48566915e-02\n",
      "  3.55177820e-02 -7.33079761e-02 -1.35491658e-02  2.11835653e-33\n",
      " -2.71114800e-02  3.53302225e-03  5.13275675e-02 -1.29332561e-02\n",
      "  7.52530172e-02 -3.21577340e-02  2.10699234e-02 -1.16666500e-02\n",
      "  2.66478839e-03 -2.37792134e-02 -4.88673151e-03  1.54482182e-02\n",
      "  1.57600585e-02  1.10918581e-01  5.09946793e-03  2.79880445e-02\n",
      "  6.17042966e-02  7.70079494e-02 -1.54758326e-03 -6.98082820e-02\n",
      " -4.05235440e-02  2.71454155e-02  2.25244323e-03  4.55447473e-02\n",
      " -3.63791101e-02  3.82062942e-02 -4.89499383e-02 -4.68270369e-02\n",
      " -9.07680020e-02 -5.10082655e-02  8.76257941e-02  4.36941646e-02\n",
      " -8.96652788e-03  4.96634133e-02 -1.87367760e-02 -2.43157707e-02\n",
      "  6.24778047e-02 -2.13541873e-02 -1.05960391e-01 -9.83136818e-02\n",
      "  1.17235482e-01 -2.59040836e-02 -4.66517694e-02  6.99379444e-02\n",
      "  2.22690571e-02  1.50071289e-02 -1.14235571e-02 -4.43646275e-02\n",
      "  1.93491783e-02  4.67829742e-02 -2.34669987e-02 -8.83642118e-03\n",
      " -5.13583720e-02  1.10073023e-01  3.70578878e-02  2.08712928e-03\n",
      "  7.72758573e-02 -3.25932056e-02 -6.93666711e-02 -2.03919178e-03\n",
      " -5.30324094e-02  1.29308626e-01 -3.20799313e-02  9.27686878e-03\n",
      "  6.66801706e-02 -3.56087908e-02 -1.32580832e-01  8.78064614e-03\n",
      " -3.68965268e-02 -8.53053853e-02  7.20850751e-02  1.40155619e-02\n",
      " -5.48412502e-02 -9.81321279e-03 -8.69681537e-02 -7.61489645e-02\n",
      " -3.70839834e-02 -3.74353640e-02 -6.62883073e-02  1.56984832e-02\n",
      " -3.42420824e-02 -2.93457713e-02 -2.55051954e-03  7.38421679e-02\n",
      " -5.88311553e-02  7.83120841e-03  1.16702311e-01 -7.41760731e-02\n",
      " -3.36695127e-02  5.65967634e-02 -4.24084365e-02  2.88883988e-02\n",
      "  2.05938332e-03 -3.93965580e-02 -6.50737360e-02 -1.39475906e-08\n",
      " -2.72883307e-02  1.20603107e-01 -4.05988581e-02  4.53112870e-02\n",
      " -1.41307553e-02 -3.73643376e-02  3.83928902e-02  8.20065439e-02\n",
      " -7.09618777e-02  2.41316836e-02  2.22364850e-02  2.19245981e-02\n",
      "  5.74574210e-02  3.97883467e-02  9.50407516e-03 -4.70468849e-02\n",
      "  1.27588054e-02  5.44280522e-02 -3.69289629e-02 -1.86687447e-02\n",
      "  1.87202469e-02  2.90528145e-02  6.13132007e-02  5.86353838e-02\n",
      " -3.20008732e-02 -9.12191626e-03  1.47366626e-02  8.00428838e-02\n",
      "  4.56062108e-02 -2.40610950e-02 -1.61237512e-02  3.36994007e-02\n",
      " -6.58808723e-02 -5.30439988e-02 -8.03904086e-02 -8.35722610e-02\n",
      "  2.12979726e-02 -4.59299348e-02  4.15264443e-02 -3.94389890e-02\n",
      " -1.12832952e-02  6.27200911e-03  3.94915566e-02  6.36184141e-02\n",
      "  1.31840393e-01  4.62604649e-02 -4.55863699e-02  2.49250643e-02\n",
      "  1.45120071e-02 -5.60757965e-02 -2.54436266e-02  7.03648552e-02\n",
      "  1.75784715e-02  4.41211425e-02  1.67691745e-02  2.08935011e-02\n",
      "  4.50255722e-03  2.32926533e-02  1.09861428e-02 -1.15152888e-01\n",
      "  5.08769117e-02  9.15466156e-03  7.19830170e-02 -1.67862121e-02]\n",
      "\n",
      "Total length of the vector: 384\n"
     ]
    }
   ],
   "source": [
    "# Here is a plain English question\n",
    "question = \"How many accidents in Virginia involved alcohol?\"\n",
    "\n",
    "# Let's run it through the model\n",
    "vector = embeddings.embed_query(question)\n",
    "\n",
    "print(\"--- Your Question ---\")\n",
    "print(f\"'{question}'\")\n",
    "\n",
    "print(\"\\n--- Becomes a 'Vector' (a list of numbers) ---\")\n",
    "#print(\"\\nFirst 5 numbers of the vector:\")\n",
    "#print(np.array(vector)[:5])\n",
    "print(np.array(vector))\n",
    "print(f\"\\nTotal length of the vector: {len(vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d5c82",
   "metadata": {},
   "source": [
    " **Now, let's create two other sentences to compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_similar = \"What is the number of drunk driving crashes in VA?\"\n",
    "text_dissimilar = \"What's the weather like in California?\"\n",
    "\n",
    "\n",
    "vector_similar = embeddings.embed_query(text_similar)\n",
    "vector_dissimilar = embeddings.embed_query(text_dissimilar)\n",
    "print(\"✅ Embedded two more sentences to compare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1da660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reshape the vectors for the function\n",
    "v_question = np.array(vector).reshape(1, -1)\n",
    "v_similar = np.array(vector_similar).reshape(1, -1)\n",
    "v_dissimilar = np.array(vector_dissimilar).reshape(1, -1)\n",
    "\n",
    "# Now, let's use 'cosine similarity' to see how \"close\" they are.\n",
    "# A score of 1.0 is a perfect match.\n",
    "sim_similar = cosine_similarity(v_question, v_similar)[0][0]\n",
    "sim_dissimilar = cosine_similarity(v_question, v_dissimilar)[0][0]\n",
    "\n",
    "print(\"--- Similarity Results (1.0 = identical) ---\")\n",
    "print(f\"Similarity to 'drunk driving': {sim_similar:.4f}\")\n",
    "print(f\"Similarity to 'California weather': {sim_dissimilar:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937c0ff",
   "metadata": {},
   "source": [
    "### **Retreive Data from Your SQL Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07857e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\"✅ RAG tools loaded. We will build this from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24319815",
   "metadata": {},
   "source": [
    "### **Load Your FARS Data**\n",
    "\n",
    "Loading small, fast sample from your CSV to act as our \"database.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample of your CSV data\n",
    "df = pd.read_csv(\"/Users/rafaelviray/Documents/FARS/Datasets & Ingestion Scripts/accident_master.csv\", nrows=50)\n",
    "\n",
    "print(\"✅ Loaded sample of FARS 'accident_master.csv'.\")\n",
    "print(\"Here's a preview:\")\n",
    "print(df[['ST_CASE', 'YEAR', 'STATE', 'FATALS']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d98d5",
   "metadata": {},
   "source": [
    "### **Building the \"R\" (Retrieval) Component**\n",
    "\n",
    "This is the core **\"technical content\"**. We serialize and index the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11722c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Serialize: Convert rows into simple \"documents\"\n",
    "print(\"Serializing CSV rows into text snippets...\")\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    # Create a simple text snippet for each accident\n",
    "    content = (\n",
    "        f\"Accident case {row['ST_CASE']} took place in {row['STATENAME']} \"\n",
    "        f\"(state code {row['STATE']}) in the year {row['YEAR']}. \"\n",
    "        f\"This incident resulted in {row['FATALS']} fatalities.\"\n",
    "    )\n",
    "    doc = Document(page_content=content, metadata={\"st_case\": row['ST_CASE']})\n",
    "    documents.append(doc)\n",
    "\n",
    "# 2. Index: Load the embedding model and build the vector store\n",
    "print(\"Loading embedding model...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Building live vector store... (This is the 'R' in RAG)\")\n",
    "vectorstore = Chroma.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"✅ Vector store is live.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b318fb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our open-source LLM\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# This is a specific question from our CSV data\n",
    "question = \"How many fatalities were in accident case 47157?\"\n",
    "\n",
    "print(f\"--- Asking the 'Dumb' LLM ---\")\n",
    "print(f\"QUESTION: {question}\\n\")\n",
    "\n",
    "# We invoke the LLM *without* RAG. It will fail.\n",
    "response = llm.invoke(question)\n",
    "\n",
    "print(\"--- RESPONSE (Hallucination) ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1449d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Augment: We create a prompt template\n",
    "# It will be \"augmented\" with the context we retrieve\n",
    "template = \"\"\"\n",
    "Answer the question based ONLY on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 2. Generate: We build the full chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# This chain links all our steps together\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ Full RAG Chain is built.\")\n",
    "print(\"This chain will now RETRIEVE, AUGMENT, and GENERATE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd33554",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Asking the 'Smart' RAG Chain ---\")\n",
    "print(f\"QUESTION: {question}\\n\")\n",
    "\n",
    "# Invoke the full RAG chain\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(\"--- RESPONSE (Grounded in FARS) ---\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fars_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
